<h2>《机器学习》 :books: </h2> 

> 周志华 著  清华大学出版社 

```html
1.机器学习的本质任务是预测。
  “机器学习”也是一门学科，研究怎样使得计算机更好地学习，亦即，是一门研究“学习算法”的学科，主要任务是评估“学习算法”的好坏
以及开发新的“学习算法”。这里的“学习算法”是计算机的学习方法，本质上是一种基于现有的数据产生预测模型的算法。

2.“假设空间”里的“假设”指的是假设函数，也就是机器学习的成果。例如我们做分类学习，那么通过数据训练后得到的分类模型
就是我们得到的假设.假设空间是指所有可能假设组成的空间。也可以说是所有在表达形式上符合任务要求的假设函数的集合。
  对于西瓜分类任务，我们要获得的假设函数的形式是：好瓜 → (色泽=*) ^ (根蒂=*) ^ (敲声=*).
  假设“色泽”、“根蒂”、“敲声”3个特征都有3种可能取值，那就有 4 * 4 * 4 + 1 = 65 种可能假设，亦即假设空间的大小为 65。

3.“归纳偏好”：在西瓜分类问题中，可能由于数据集的原因，我们会得到多个符合数据集的假设函数，比如：
    好瓜 → (色泽 = 墨绿) ^ (根蒂 = 蜷缩) ^ (敲声 = 沉闷)
    好瓜 → (色泽 = 青绿) ^ (根蒂 = *) ^ (敲声 = 沉闷)
这所有训练后得到的假设组成的空间称为“版本空间”。
   那么版本空间中哪一个假设比较好？
   如果我们认为越精细越好，则选择: 好瓜 → (色泽 = 墨绿) ^ (根蒂 = 蜷缩) ^ (敲声 = 沉闷)
   如果我们认为越粗略越好，则选择: 好瓜 → (色泽 = 青绿) ^ (根蒂 = *) ^ (敲声 = 沉闷)
   像上面那样，计算机的学习算法基于某种偏好认为某个假设比其他假设好，那么我们说这个学习算法有“归纳偏好”。
事实上所有“学习算法”都有归纳偏好，而且一般来说会偏好那些形式简单的假设。

4.人类观察事物时，是通过观察事物的本质特征来认识事物的。比如观察西瓜，会观察西瓜的色泽、根蒂、敲声等特征。
  假设我们收集了一批关于西瓜的数据：
   (色泽 = 青绿; 根蒂 = 蜷缩; 敲声 = 浊响)
   (色泽 = 墨绿; 根蒂 = 稍蜷; 敲声 = 沉闷)
   (色泽 = 浅白; 根蒂 = 硬挺; 敲声 = 清脆)
    ······
   假设我们希望用这一批数据来让计算机学习:
  (1) 样本、示例、记录 —— 这批数据里的每对括号。
  (2) 数据集 —— 这组样本(示例、记录)的集合。
  (3) 特征、属性 —— 色泽、根蒂、敲声等反映一个事物的本质的可观察方面。
  (4) 属性值 —— 青绿、墨绿、蜷缩、浊响等，是属性的取值。
  (5) 属性空间、样本空间、输入空间 —— 属性长成的空间。这似乎是线性代数的语言，亦即把属性当作坐标轴，形成一个空间，
那么样本就是这个空间中一个个的点。例如：把“色泽”、“根蒂”、“敲声”作为坐标轴，则生成了一个三维空间，
每个西瓜都是这个空间里的一个点。
  (6) 维数 —— 样本空间的坐标轴数，也就是数据集的特征数量。本例中的维数是 3。
  (7) 假设 —— 也称假设函数，指计算机通过学习后得到的一个函数(预测模型)。
  (8) 标记 —— 关于样本结果的信息，比如一个(色泽 = 青绿; 根蒂 = 蜷缩; 敲声 = 浊响)的西瓜是好瓜，
那么“好瓜”就是(色泽 = 青绿; 根蒂 = 蜷缩; 敲声 = 浊响)这个样本的标记。
  (9) 样例 —— 带有标记的样本，比如(色泽 = 青绿; 根蒂 = 蜷缩; 敲声 = 浊响)，好瓜。
  (10) 标记空间、输出空间 —— 所有标记的集合。本例中就是指{好瓜、坏瓜}。
  (11) 泛化 —— 如果用某个数据集的样本训练出的一个模型(假设函数)，能够适用于新的样本数据，就说这个模型具有泛化能力。
模型能适用于越多的新数据，则说明其泛化能力越强。

5.NFL(No Free Lunch)定理，翻译过来就是“没有免费午餐”定理，说的是在机器学习中，在没有给定具体问题的情况下，
或者说面对的是所有问题的情况下，没有一种算法能说得上比另一种算法好。换成我们的俗话讲，就是“不存在放之四海而皆准的方法”。
只有在给定某一问题，比如说给“用特定的数据集给西瓜进行分类”，才能分析并指出某一算法比另一算法好。
这就要求我们具体问题具体分析，而不能指望找到某个算法后，就一直指望着这个“万能”的算法。
  这大概也是 no free lunch 名字的由来吧。
  定理推导的思路是证明对于某个算法 a，它在训练集以外的所有样本的误差，与 a 本身无关。
  误差是怎样表示，或者说怎样计算出来的？简单起见，只考虑二分类问题。那么误差就是分类器错判的个数与样本总数的比
      E = 误判数 / 总数。
  其次我们要明确，一个算法，会产生很多不同的假设。更详细的说，一个算法的结果就是一个函数 h，但是 h 的参数不同，
那么就会有 h1，h2 等不同的假设函数。最典型的是 h = kx + b。只要参数 k、b 不同，那么函数 h 就不同了。
  对于某个算法 a，它在训练集以外的所有样本的误差，就是它所能产生的所有假设 h，在训练集以外的所有样本上的误判率的和。
  对于某个假设 h，“h 在某个数据集上的误差”与“在某个数据集中抽取一个能让 h 误判的样本的概率”是等价的问题。
```

> NFL(No Free Lunch)定理的具体证明详见：<a href="https://www.jianshu.com/p/cbe8e0fe7b2c">url</a>

```html
6.P5 假设空间的规模问题。
  (1) 某一属性值无论取什么都合适，我们用通配符 “*” 来表示。
  (2) 世界上没有，我们用 “∅” 来表示。

7.“奥卡姆剃刀”原则：“若有多个假设与观察一致，则选最简单的那个”。
   预测((离散值：分类-二分类(正类, 反类/负类), 多分类); 连续值)。
   学习任务(监督：有标记(分类, 回归); 无监督：无标记(聚类))。
   科学推理(归纳(特殊->一般：泛化); 演绎(一般->特殊：特化))。
   归纳学习(广义(从样例中学习); 狭义(从训练数据中学得概念，最基本：布尔概念学习))。

8.评估学习器的基本思想是：
  (1) 学习器误差越小越好。对于分类任务，分类错误的样本数占总样本数的比率越小越好。
对于回归预测，预测值与真实值的差越小越好。
  (2) 学习器泛化能力越强越好。也就是说学习能力不仅在训练样本上要表现好，在新的样本上的表现也要好。
不能像书呆子一样在学校表现很好，但一进入社会就一塌糊涂。因此，我们通常衡量一个学习器的泛化误差，
也就是一个训练好的学习器在新样本上的误差表现。

9.当只有一个数据集，并且既要训练，又要测试的时候，怎么办？
  (1) 留出法：当只有一个数据集的时候，用一部分来训练，一部分来测试。而且训练数据和测试数据没有交集。
通常会用 60% 到 80% 的数据作为训练集，剩下的作为测试集。需要注意的是，在选择训练集(或者测试集)的时候要采用分层抽样的方法。
就像刷题一样，训练集和测试集都要有相近比例的题型，不能训练集全是选择题，测试集全是论述题，
应该训练集和测试集都包含选择题和测试题，而且比例要一致，都是八成选择题，两成论述题。
一次的训练-测试结果可能不够科学，最好划分不同的训练集和测试集，做多次训练-测试，将测试结果(错误率、查准率之类的)取平均。
  (2) 交叉检验法：这是在 “留出法” 的基础上改进的方法。先将数据集分为 k 个大小相似的互斥子集
(当然，每个子集的产生都要用分层抽样进行)。每次用 k-1 个子集作为训练集，剩下的一个作为测试集。
这样就可以进行 k 次训练-测试。k 的测试结果的平均值就是最终的测试结果。
  (3) 自助法：上述两种方法都是在原本作为训练集的数据中抽出一部分作为测试集，因此训练集的规模不可避免地减少了，
训练效果也就受到了影响。自助法则是一中比较好的缓解方法。假设有一个包含 m 个样本的数据集 D。
对这个数据集进行 m 次有放回的抽样，则得到了一个含有 m 个样本的数据集 D'。 D' 相对于原数据集 D，规模没有减少，
只是 D' 中有部分样本是重复出现的。所以在抽样中没有抽到的样本就作为测试集，D' 就作为训练集。按照概率论推导可知，
一般来说抽样中会有三分之一的样本没有被抽到，也就是说测试集大小为数据集 D 大小的三分之一。
   在数据集比较大时多采用留出法和交叉检验法，当数据集比较小是采用自助法。

10.在测试一个学习器时，有哪些测试指标可以使用？
  (1) 错误率(error)：最常用的测试指标就是错误率(或者精度)。对于一次分类任务，如果分类错误的样本数为 a，总样本数为 m，
则错误率 E = a / m.(精度为 1 - a / m)。比如为 100 个西瓜分类，有 10 个分错了，错误率就是 10%。
  (2) 均方误差(mean squared error)：“错误率”一般针对分类任务，回归预测则用均方误差，即各次预测值与真实值的差的平方的和：
$$ \sum_{i = 1}^n (y_预 - y_真)^2 $$; 可以认为是各次预测的误差的累加。
  (3) 查准率(precision)：也就是检索出来的结果中准确的结果所占的比例。比如找出 100 个西瓜中的好瓜，找出 50 个，
但这 50 个中只有 40 个是真正的好瓜，则查准率为 80%。
  (4) 查全率(recall)：也就是希望检索的结果中被检索出来的比例。比如找出 100 个西瓜中的好瓜，找出 40 个，
但真正的好瓜有 50个，则查全率为 80%。
  (5) ROC 曲线: 很多二分类学习器的分类方法是计算出每一个样本作为正例的概率，然后按照概率大小对样本排序，
最后确定一个临界概率(阀值)，大于临界概率的认定为正例，其余为反例。以西瓜分类为例。有些西瓜是好瓜的概率高，
有些西瓜是好瓜的概率低。把这些西瓜按照概率排序，然后取 50% 作为临界概率。概率大于 50% 的认为是好瓜，否则为坏瓜。
因此这个排序的质量很重要。那就产生两个指标：真正例率(“选出的好瓜”真正的好瓜占所有的好瓜的比例，也就是好瓜的查准率)，
和假正例率(“选出的好瓜”中坏瓜占所有坏瓜的比例)。对于每一个临界概率，都有一个对应的真正例率和假正例率。
把各个临界概率对应的真正例率和假正例率绘成图就是 ROC 图。
  (6) AUC：AUC 就是 ROC 曲线中右下方区域的面积。AUC 判断一个分类用的排序队列的好坏。

11.知道了两个学习器的某个指标，比如错误率，A 学习器的错误率低于B学习器的错误率，能否认为 A 学习器质量比 B 学习器好？
   不能。首先一次的测试结果可能有误差，需要多次测试然后取平均。所以应该比较平均错误率。
   其次一个学习器的平均错误率比另一个的低，也只是一次的比较结果，可能有误差。
   若要比较两个学习器的某项置标，要用到统计学的假设检验。
   比如用 t 检验比较两个学习器的平均错误率。用方差分析和多重比较来比较多个学习器的某项性能。
```
